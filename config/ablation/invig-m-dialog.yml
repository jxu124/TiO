
env:
    path_ofa: "/mnt/bn/hri-lq/projects/VLDD/OFA"
    path_invig: "/mnt/bn/hri-lq/projects/VLDD/OFA-Invig"
    path_tokenizer: "/mnt/bn/hri-lq/projects/VLDD/Link/ofa-pretrain/hf/ofa-large"
    path_exclude_images: "/mnt/bn/hri-lq/datasets/hf-cache/test_images.json"
    path_images:
        coco: "/mnt/bn/hri-lq/datasets/images/coco"
        visdial: "/mnt/bn/hri-lq/datasets/images/visdial"
        openimages_v1.2: "/mnt/bn/hri-lq/datasets/images/openimages_v1.2"
        cc_sbu_align: "/mnt/bn/hri-lq/datasets/images/cc_sbu_align"
        cc3m_llava: "/mnt/bn/hri-lq/datasets/images/cc3m_llava"

hparam:
    max_src_length: 240
    max_tgt_length: 320

train:  # 目标1M
  - name: "invig"  # 17k
    path: /mnt/bn/hri-lq/datasets/hf-cache/invig
    tasks: ["invig_question", "invig_answer", "invig_grounding"]
    probs: [1, 1, 1]
  - name: guesswhat  # 92k （68k）
    path: /mnt/bn/hri-lq/datasets/hf-cache/guesswhat
    tasks: ["guesswhat_question", "guesswhat_answer", "guesswhat_grounding"]
    probs: [1, 1, 1]
  # - name: visdial  # 123k (103k)
  #   path: /mnt/bn/hri-lq/datasets/hf-cache/visdial
  #   tasks: ["visdial_question", "visdial_answer", "visdial_caption"]
  #   probs: [0.3, 0.3, 0.1]
  - name: refcoco  # 42k (31k)
    path: /mnt/bn/hri-lq/datasets/hf-cache/refcoco
    tasks: ["refcoco_grounding"]
    probs: [0.3]
  - name: refcocog  # 42k (33k)
    path: /mnt/bn/hri-lq/datasets/hf-cache/refcocog
    tasks: ["refcoco_grounding"]
    probs: [0.3]
  - name: refcocoplus  # 42k (31k)
    path: /mnt/bn/hri-lq/datasets/hf-cache/refcocoplus
    tasks: ["refcoco_grounding"]
    probs: [0.3]
  # - name: cc_sbu_align  # 3k (3k)
  #   path: /mnt/bn/hri-lq/datasets/hf-cache/cc_sbu_align
  #   tasks: ["cc_sbu_align_caption"]
  #   probs: [1]
  # - name: "llava_instruct_150k"  # 150k (129k)
  #   path: "/mnt/bn/hri-lq/datasets/hf-cache/llava_instruct_150k"
  #   tasks: ["llava_instruct_150k"]
  #   probs: [0.7]
  # - name: "llava_conversation_58k"  # 58k (46k)
  #   path: "/mnt/bn/hri-lq/datasets/hf-cache/llava_conversation_58k"
  #   tasks: ["llava_conversation_58k"]
  #   probs: [1.0]
  # - name: "llava_complex_reasoning_77k"  # 77k (63k)
  #   path: "/mnt/bn/hri-lq/datasets/hf-cache/llava_complex_reasoning_77k"
  #   tasks: ["llava_complex_reasoning_77k"]
  #   probs: [0.7]
  # - name: "llava_detail_23k"  # 23k (17k)
  #   path: "/mnt/bn/hri-lq/datasets/hf-cache/llava_detail_23k"
  #   tasks: ["llava_detail_23k"]
  #   probs: [0.7]
  - name: "openimages"  # 29k
    path: "/mnt/bn/hri-lq/datasets/hf-cache/openimages_v1.2"
    tasks: ['openimages_detection']
    probs: [0.5]

validation: 
  - name: "invig"  # ~1k
    path: /mnt/bn/hri-lq/datasets/hf-cache/invig
    tasks: ["invig_grounding"]
    probs: [1]
  # - name: guesswhat  # ~20k
  #   path: /mnt/bn/hri-lq/datasets/hf-cache/guesswhat
  #   tasks: ["guesswhat_grounding"]
  #   probs: [0.3]

test:
  guesswhat_grounding: 
    path: /mnt/bn/hri-lq/datasets/hf-cache/guesswhat
    task: "guesswhat_grounding"
    style: 0
  invig_grounding: 
    path: /mnt/bn/hri-lq/datasets/hf-cache/invig
    task: "invig_grounding"
    style: 0
  guesswhat_oracle: 
    path: /mnt/bn/hri-lq/datasets/hf-cache/guesswhat
    task: "guesswhat_oracle"
    style: 0
